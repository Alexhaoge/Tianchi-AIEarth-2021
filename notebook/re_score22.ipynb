{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置种子\n",
    "def set_seed(seed = 427):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据导入\n",
    "def load_data2():\n",
    "    # CMIP data    \n",
    "    train = xr.open_dataset('../tcdata/enso_round1_train_20210201/CMIP_train.nc')\n",
    "    label = xr.open_dataset('../tcdata/enso_round1_train_20210201/CMIP_label.nc')    \n",
    "   \n",
    "    train_sst = train['sst'][:, :12].values  # (4645, 12, 24, 72)截取前12项\n",
    "    train_sst= np.concatenate((train_sst[:151*5],train_sst[151*9:151*12],train_sst[151*13:]))  \n",
    "    train_t300 = train['t300'][:, :12].values\n",
    "    train_t300= np.concatenate((train_t300[:151*5],train_t300[151*9:151*12],train_t300[151*13:]))  \n",
    "    train_ua = train['ua'][:, :12].values\n",
    "    train_ua= np.concatenate((train_ua[:151*5],train_ua[151*9:151*12],train_ua[151*13:]))  \n",
    "    train_va = train['va'][:, :12].values\n",
    "    train_va= np.concatenate((train_va[:151*5],train_va[151*9:151*12],train_va[151*13:]))  \n",
    "    train_label = label['nino'][:, 12:36].values\n",
    "    train_label= np.concatenate((train_label[:151*5],train_label[151*9:151*12],train_label[151*13:]))  \n",
    "    \n",
    "    #train_ua = np.nan_to_num(train_ua)#缺失值补0\n",
    "    #train_va = np.nan_to_num(train_va)\n",
    "    #train_t300 = np.nan_to_num(train_t300)\n",
    "    #train_sst = np.nan_to_num(train_sst)\n",
    "    # SODA data    \n",
    "    train2 = xr.open_dataset('../tcdata/enso_round1_train_20210201/SODA_train.nc')\n",
    "    label2 = xr.open_dataset('../tcdata/enso_round1_train_20210201/SODA_label.nc')\n",
    "    \n",
    "    train_sst2 = train2['sst'][:, :12].values  # (3890, 12, 24, 72)\n",
    "    train_t3002 = train2['t300'][:, :12].values\n",
    "    train_ua2 = train2['ua'][:, :12].values\n",
    "    train_va2 = train2['va'][:, :12].values\n",
    "    train_label2 = label2['nino'][:, 12:36].values\n",
    "\n",
    "    print('Train samples: {}, Valid samples: {}'.format(len(train_label), len(train_label2)))\n",
    "\n",
    "    dict_train = {\n",
    "        'sst':train_sst,\n",
    "        't300':train_t300,\n",
    "        'ua':train_ua,\n",
    "        'va': train_va,\n",
    "        'label': train_label}\n",
    "    dict_valid = {\n",
    "        'sst':train_sst2,\n",
    "        't300':train_t3002,\n",
    "        'ua':train_ua2,\n",
    "        'va': train_va2,\n",
    "        'label': train_label2}\n",
    "    train_dataset = EarthDataSet(dict_train)\n",
    "    valid_dataset = EarthDataSet(dict_valid)\n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "class EarthDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['sst'])\n",
    "\n",
    "    def __getitem__(self, idx):   \n",
    "        return (self.data['sst'][idx], self.data['t300'][idx], self.data['ua'][idx], self.data['va'][idx]), self.data['label'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleSpatailTimeNN(nn.Module):\n",
    "    def __init__(self, n_cnn_layer:int=1, kernals:list=[3,3], n_lstm_units:int=64):\n",
    "        super(simpleSpatailTimeNN, self).__init__()\n",
    "        self.conv1 = nn.ModuleList([nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(2,2)),\n",
    "                                    nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True)]) \n",
    "        self.conv2 = nn.ModuleList([nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(2,2)),\n",
    "                                    nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True)])\n",
    "        self.conv3 = nn.ModuleList([nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(2,2)),\n",
    "                                    nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True)])\n",
    "        self.conv4 = nn.ModuleList([nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(2,2)),\n",
    "                                    nn.Conv2d(in_channels=12, out_channels=12, kernel_size=3),\n",
    "                                    nn.ReLU(inplace = True)])\n",
    "        self.pool1 = nn.AdaptiveAvgPool2d((22, 1))\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d((1, 70))\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((1, 128))\n",
    "        self.batch_norm = nn.BatchNorm1d(12, affine=False)\n",
    "        self.lstm = nn.LSTM(9*33*4, n_lstm_units, 2, bidirectional=True)\n",
    "        self.linear = nn.Linear(128, 24)\n",
    "\n",
    "    def forward(self, sst, t300, ua, va):\n",
    "        for conv1 in self.conv1:\n",
    "            sst = conv1(sst)  # batch * 12 * (24 - 2-2) * (72 -2-2)\n",
    "        for conv2 in self.conv2:\n",
    "            t300 = conv2(t300)\n",
    "        for conv3 in self.conv3:\n",
    "            ua = conv3(ua)\n",
    "        for conv4 in self.conv4:\n",
    "            va = conv4(va)\n",
    "\n",
    "        sst = torch.flatten(sst, start_dim=2)  # batch * 12 * 1540\n",
    "        t300 = torch.flatten(t300, start_dim=2)\n",
    "        ua = torch.flatten(ua, start_dim=2)\n",
    "        va = torch.flatten(va, start_dim=2)  # if flat, lstm input_dims = 1540 * 4              \n",
    "            \n",
    "        x = torch.cat([sst, t300, ua, va], dim=-1) #在内层合并 batch*12*1540*4\n",
    "        x = self.batch_norm(x)\n",
    "        x, _ = self.lstm(x)#输入1540*4,64hidden,2layer且双向 输出batch*(128=64*2)\n",
    "        x = self.pool3(x).squeeze(dim=-2)\n",
    "        x = self.linear(x)#128-->24\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#模型\n",
    "\n",
    "class simpleSpatailTimeNN(nn.Module):\n",
    "    def __init__(self, n_cnn_layer:int=1,n_lstm_units:int=64):\n",
    "        super(simpleSpatailTimeNN, self).__init__()\n",
    "        self.conv1 = nn.ModuleList([nn.Conv2d(in_channels=12, out_channels=12,kernel_size=3),#22*70\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(2,2)),#11*35\n",
    "                                    nn.Conv2d(in_channels=12, out_channels=12,kernel_size=3),#9*33\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(3,3))] ),#3*11 \n",
    "        self.conv2 = nn.ModuleList([nn.Conv2d(in_channels=12, out_channels=12,kernel_size=3),#22*70\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(2,2)),#11*35\n",
    "                                    nn.Conv2d(in_channels=12, out_channels=12,kernel_size=3),#9*33\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(3,3))] ),#3*11 \n",
    "        self.conv4 = nn.ModuleList([nn.Conv2d(in_channels=12, out_channels=12,kernel_size=3),#22*70\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(2,2)),#11*35\n",
    "                                    nn.Conv2d(in_channels=12, out_channels=12,kernel_size=3),#9*33\n",
    "                                    nn.ReLU(inplace = True),\n",
    "                                    nn.AvgPool2d(kernel_size=(3,3))] ),#3*11 \n",
    "        self.pool1 = nn.AdaptiveAvgPool2d((22, 1))\n",
    "        self.pool2 = nn.AdaptiveAvgPool2d((1, 70))\n",
    "        self.pool3 = nn.AdaptiveAvgPool2d((1, 128))\n",
    "        self.batch_norm = nn.BatchNorm1d(12, affine=False)\n",
    "        self.lstm = nn.LSTM(33 * 4, n_lstm_units, 2, bidirectional=True)\n",
    "        self.linear = nn.Linear(128, 24)\n",
    "\n",
    "    def forward(self, sst, t300, ua, va):\n",
    "        for conv1 in self.conv1:\n",
    "            sst = conv1(sst)  # batch * 12 * (3*11)\n",
    "        for conv2 in self.conv2:\n",
    "            t300 = conv2(t300)\n",
    "        for conv3 in self.conv3:\n",
    "            ua = conv3(ua)\n",
    "        for conv4 in self.conv4:\n",
    "            va = conv4(va)\n",
    "\n",
    "        sst = torch.flatten(sst, start_dim=2)  # batch *33\n",
    "        t300 = torch.flatten(t300, start_dim=2)\n",
    "        ua = torch.flatten(ua, start_dim=2)\n",
    "        va = torch.flatten(va, start_dim=2)  # if flat, lstm input_dims = 1540 * 4              \n",
    "            \n",
    "        x = torch.cat([sst, t300, ua, va], dim=-1) #在内层合并 batch*12*33*4\n",
    "        x = self.batch_norm(x)\n",
    "        x, _ = self.lstm(x)#输入33*4,64hidden,2layer且双向 输出batch*(128=64*2)\n",
    "        x = self.pool3(x).squeeze(dim=-2)\n",
    "        x = self.linear(x)#128-->24\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function\n",
    "def coreff(x, y):\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    c1 = sum((x - x_mean) * (y - y_mean))\n",
    "    c2 = sum((x - x_mean)**2) * sum((y - y_mean)**2)\n",
    "    return c1/np.sqrt(c2)\n",
    "\n",
    "def rmse(preds, y):\n",
    "    return np.sqrt(sum((preds - y)**2)/preds.shape[0])\n",
    "\n",
    "def eval_score(preds, label):\n",
    "    # preds = preds.cpu().detach().numpy().squeeze()\n",
    "    # label = label.cpu().detach().numpy().squeeze()\n",
    "    acskill = 0\n",
    "    RMSE = 0\n",
    "    a = 0\n",
    "    a = [1.5]*4 + [2]*7 + [3]*7 + [4]*6\n",
    "    for i in range(24):\n",
    "        RMSE += rmse(label[:, i], preds[:, i])\n",
    "        cor = coreff(label[:, i], preds[:, i])\n",
    "    \n",
    "        acskill += a[i] * np.log(i+1) * cor\n",
    "    return 2/3 * acskill - RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "fit_params = {\n",
    "    'n_epochs' : 50,\n",
    "    'learning_rate' : 1e-4,\n",
    "    'batch_size' : 128,\n",
    "}\n",
    "\n",
    "\n",
    "def train():\n",
    "    #set_seed()\n",
    "    train_dataset, valid_dataset = load_data2()      \n",
    "    train_loader = DataLoader(train_dataset, batch_size=fit_params['batch_size'])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=fit_params['batch_size'])\n",
    "\n",
    "    model = simpleSpatailTimeNN()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=fit_params['learning_rate'])\n",
    "    loss_fn = nn.MSELoss()   \n",
    "    \n",
    "    model.to(device)\n",
    "    loss_fn.to(device)\n",
    "\n",
    "    for i in range(fit_params['n_epochs']):\n",
    "        model.train()\n",
    "        for step, ((sst, t300, ua, va), label) in enumerate(train_loader):                \n",
    "            sst = sst.to(device).float()\n",
    "            t300 = t300.to(device).float()\n",
    "            ua = ua.to(device).float()\n",
    "            va = va.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            label = label.to(device).float()\n",
    "            preds = model(sst, t300, ua, va)\n",
    "            loss = loss_fn(preds, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #print('Step: {}, Train Loss: {}'.format(step, loss))\n",
    "\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for step, ((sst, t300, ua, va), label) in enumerate(valid_loader):\n",
    "            sst = sst.to(device).float()\n",
    "            t300 = t300.to(device).float()\n",
    "            ua = ua.to(device).float()\n",
    "            va = va.to(device).float()\n",
    "            label = label.to(device).float()\n",
    "            preds = model(sst, t300, ua, va)\n",
    "            y_pred.append(preds)\n",
    "            y_true.append(label)\n",
    "\n",
    "        y_true = torch.cat(y_true, axis=0)\n",
    "        y_pred = torch.cat(y_pred, axis=0)\n",
    "        sco = eval_score(y_true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "        print('Epoch: {}, Valid Score {}'.format(i+1,sco))\n",
    "\n",
    "        # torch.save(self.model.state_dict(), '../user_data/ref.pkl')\n",
    "        #torch.save(model, '../notebook/score22_original')\n",
    "        print('Model saved successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除缺失值\n",
    "#新结构:先CNN卷四个分量kernel=5(20*68),然后avg pool 再卷积(stride=(5,4)-->4*17)再avg pool 再卷积(2*5),flatten再加月份 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3890, Valid samples: 100\n",
      "Epoch: 1, Valid Score -14.052612775470948\n",
      "Model saved successfully\n",
      "Epoch: 2, Valid Score -6.453047160472959\n",
      "Model saved successfully\n",
      "Epoch: 3, Valid Score -1.521226632195738\n",
      "Model saved successfully\n",
      "Epoch: 4, Valid Score -2.0664745389544947\n",
      "Model saved successfully\n",
      "Epoch: 5, Valid Score 0.8222242320630535\n",
      "Model saved successfully\n",
      "Epoch: 6, Valid Score 9.637843065630417\n",
      "Model saved successfully\n",
      "Epoch: 7, Valid Score 21.527406711905222\n",
      "Model saved successfully\n",
      "Epoch: 8, Valid Score 31.458690347860685\n",
      "Model saved successfully\n",
      "Epoch: 9, Valid Score 39.27485391531059\n",
      "Model saved successfully\n",
      "Epoch: 10, Valid Score 45.74728350914828\n",
      "Model saved successfully\n",
      "Epoch: 11, Valid Score 51.032818361132364\n",
      "Model saved successfully\n",
      "Epoch: 12, Valid Score 55.31213904633023\n",
      "Model saved successfully\n",
      "Epoch: 13, Valid Score 59.0206992269091\n",
      "Model saved successfully\n",
      "Epoch: 14, Valid Score 62.42948315256115\n",
      "Model saved successfully\n",
      "Epoch: 15, Valid Score 65.49780368404375\n",
      "Model saved successfully\n",
      "Epoch: 16, Valid Score 67.50735317487575\n",
      "Model saved successfully\n",
      "Epoch: 17, Valid Score 70.25112908307628\n",
      "Model saved successfully\n",
      "Epoch: 18, Valid Score 73.72469161998933\n",
      "Model saved successfully\n",
      "Epoch: 19, Valid Score 76.42127348723388\n",
      "Model saved successfully\n",
      "Epoch: 20, Valid Score 78.3802940283746\n",
      "Model saved successfully\n",
      "Epoch: 21, Valid Score 79.77827669954334\n",
      "Model saved successfully\n",
      "Epoch: 22, Valid Score 80.84698184876387\n",
      "Model saved successfully\n",
      "Epoch: 23, Valid Score 81.93166035579124\n",
      "Model saved successfully\n",
      "Epoch: 24, Valid Score 82.76150217062111\n",
      "Model saved successfully\n",
      "Epoch: 25, Valid Score 83.25530901132568\n",
      "Model saved successfully\n",
      "Epoch: 26, Valid Score 83.64796988728358\n",
      "Model saved successfully\n",
      "Epoch: 27, Valid Score 83.91290562238068\n",
      "Model saved successfully\n",
      "Epoch: 28, Valid Score 84.14414289044986\n",
      "Model saved successfully\n",
      "Epoch: 29, Valid Score 84.3322013298283\n",
      "Model saved successfully\n",
      "Epoch: 30, Valid Score 84.48913669288153\n",
      "Model saved successfully\n",
      "Epoch: 31, Valid Score 84.60542345909191\n",
      "Model saved successfully\n",
      "Epoch: 32, Valid Score 84.71370248697548\n",
      "Model saved successfully\n",
      "Epoch: 33, Valid Score 84.76243822921423\n",
      "Model saved successfully\n",
      "Epoch: 34, Valid Score 84.81841913161088\n",
      "Model saved successfully\n",
      "Epoch: 35, Valid Score 84.83281735361358\n",
      "Model saved successfully\n",
      "Epoch: 36, Valid Score 84.83909824588031\n",
      "Model saved successfully\n",
      "Epoch: 37, Valid Score 84.79823816602814\n",
      "Model saved successfully\n",
      "Epoch: 38, Valid Score 84.78320522081462\n",
      "Model saved successfully\n",
      "Epoch: 39, Valid Score 84.71320808406892\n",
      "Model saved successfully\n",
      "Epoch: 40, Valid Score 84.66311497491827\n",
      "Model saved successfully\n",
      "Epoch: 41, Valid Score 84.58344583850598\n",
      "Model saved successfully\n",
      "Epoch: 42, Valid Score 84.50262567240142\n",
      "Model saved successfully\n",
      "Epoch: 43, Valid Score 84.40870055625412\n",
      "Model saved successfully\n",
      "Epoch: 44, Valid Score 84.31256181249846\n",
      "Model saved successfully\n",
      "Epoch: 45, Valid Score 84.18601730348682\n",
      "Model saved successfully\n",
      "Epoch: 46, Valid Score 84.08917375448448\n",
      "Model saved successfully\n",
      "Epoch: 47, Valid Score 83.95331529311585\n",
      "Model saved successfully\n",
      "Epoch: 48, Valid Score 83.81795462887146\n",
      "Model saved successfully\n",
      "Epoch: 49, Valid Score 83.6584698327486\n",
      "Model saved successfully\n",
      "Epoch: 50, Valid Score 83.49968663970331\n",
      "Model saved successfully\n"
     ]
    }
   ],
   "source": [
    "train()\n",
    "#details:1.用CMIP的值训练SODA,训练出前12个月[sst,t300,ua,va]预测后24个月nino的模型\n",
    "#        2.结构:[sst,t300.ua,va]按照12个月分别过3*3卷积层(4channel,12*(24-2)*(72-2)),再flatten经纬度(4 features,12*1540)，最内层合并4个feature:(12*1540*4) 过batchnorm ,lstm：双向两层，输出batch*12*(64*2)  对12个月hidden平均池化，得到batch*128,全连接到24个月\n",
    "#problems:1.缺失值填0 2.优化函数是MSE 3.没有利用前12个月的nino\n",
    "#优化方向:需要突出空间经纬度相关性而不是直接flatten，更改网络结构，区分CMIP和SODA,ua va取滑动平均"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
